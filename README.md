# Blog-for-adaboost
This is a material index for writing a blog about adaboost.

http://www.52caml.com/head_first_ml/ml-chapter6-boosting-family/  第06章：深入浅出ML之Boosting家族，但可以想象的是，随着spark的进一步发展，该分布式计算平台会变的非常重，功能也会越来越多。离专注、专一和极致的解决某类问题越来越远，对每一类问题给出的解决方案并不会特别好。

http://chuansong.me/n/1146911642859 MXNet专栏 | 李沐：深度学习·炼丹入门 

http://geek.csdn.net/news/detail/201207 揭秘Kaggle神器xgboost

http://blog.csdn.net/heyongluoyao8/article/details/49408131 在分类中如何处理训练集中不平衡问题，这里提到了一种人工数据生成办法，SMOTE

https://www.zhihu.com/topic/19719221/hot adaboost,提到泛化误差的问题，讨论了很多。

虽然鲍捷老师一直在倡导智能金融，并身体力行，但我心里一直嘀咕的是，这事不好办。

前一段时间，有道翻译还蛮靠谱的，但现在也不行了，国内学者或者学生越来越喜欢用英文写作了，从国外搬砖，不得不翻译成中文的，如今和向国内学者或学生学习都得用英文了，
这事就累得慌了。有段时间我再想，有道这么厉害，以后不用学英语了，但现在想明白了，是可以不用学英语了，但得交钱。

周志华老师《机器学习》关于adaboost一节介绍的不多，但在25th adaboost讲了很多。

https://cseweb.ucsd.edu/classes/fa01/cse291/AdaBoost.pdf 2001年Freund and Schaipre 写的简介。

http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Eric-Boosting304FinalRpdf.pdf MIT adaboost讲义。

http://mccormickml.com/2013/12/13/adaboost-tutorial/ 有一点内容，不重要。

http://www.multiboost.org/ 多分类boost软件。

xgboost，最早用在300k数据集上，用randomforest直接卡死，用xgboost直接通过，很surprise。

https://github.com/luispedro/milk 一款python和c++加速的adaboost软件。

http://totoharyanto.staff.ipb.ac.id/files/2012/10/Building-Machine-Learning-Systems-with-Python-Richert-Coelho.pdf 和上面是同一个作者。

https://www.zhihu.com/question/23003213 回头要看看python和C+要怎样混合编程。

Nov 13th,2017

https://www.zhihu.com/topic/20035241/hot 关于xgboost的讨论，马超讲了vc维，周在《机器学习》计算学习理论一章里讲到vc、Rademacher复杂度、
稳定性。马超：而特征的多样性也正是为什么工业界很少去使用 svm 的一个重要原因之一？

https://github.com/TracyMcgrady6 马超的github？

https://www.jiqizhixin.com/articles/2017-11-08-3 为什么XGBoost在机器学习竞赛中表现如此卓越？挪威科技大学 Didrik Nielsen 的硕士论文《使用 XGBoost 的树提升：为什么 XGBoost 能赢得「每一场」机器学习竞赛？（Tree Boosting With XGBoost - Why Does XGBoost Win "Every" Machine Learning Competition?）》

http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf 搞了半天，还得弄明白VC维

https://github.com/vividfree/alphabet 罗维的github，很多内容，我想知道怎么写C++？博客也很好，就是乱了一点。

http://txshi-mt.com/2017/08/20/NTUML-7-the-VC-Dimension/ 关于VC维，有点难

http://web.cecs.pdx.edu/~mm/MachineLearningWinter2017/EnsembleLearning.pdf 集成学习示例，比较详细

http://web.cecs.pdx.edu/~mm/MachineLearningSpring2017/EnsembleLearningExerciseSolutions.pdf 上例中计算解释

http://lamda.nju.edu.cn/MainPage.ashx 南大机器学习与数据挖掘研究所网站

https://petolau.github.io/Ensemble-of-trees-for-forecasting-time-series/ 集成学习在电力消费上的预测

http://www.liaad.up.pt/area/jgama/InfSys2017.pdf 集成学习在流数据分析的应用

http://docs.w3cub.com/scikit_learn/auto_examples/ensemble/plot_adaboost_hastie_10_2/ Discrete versus Real AdaBoost

https://www.leiphone.com/news/201707/JSAaQzOebhHHKuTN.html 如何用自动机器学习实现神经网络进化 

https://www.leiphone.com/news/201705/NlTc7oObBqh116Z5.html 南京大学俞扬博士万字演讲全文：强化学习前沿（上）

https://github.com/xiahouzuoxin/notes/tree/master/essays 有一些无聊的东西

http://mnews.onlinedown.net/trends/83553.html 微软研院的时空数据分析，很好的资料

https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/ 这里提到boosting确实可以减少方差和偏差。

http://adataanalyst.com/machine-learning/adaboost-python-3/ 介绍了adaboost的python实现

https://github.com/nathanntg/adaboost adaboost复杂实现

https://github.com/alinagithub/Adaboost/blob/master/AdaBoost.py 看不懂实现

https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/ 很多典故

http://xxuan.me/2017-03-24-adaboost.html 中文adaboost，有python代码

https://www.zhihu.com/question/29138020 如何自学python 这个厉害 还有南洋理工大学的博士 分享 也很厉害

https://github.com/lijin-THU 还不错，介绍python和ml

http://www.jianshu.com/u/212ef8ed6ac2 爬虫或python必备

Nov 14th,2017

https://www.leiphone.com/news/201709/QuBqR1h6I7yglwbH.html 周志华CAIS大会的演讲

https://www.leiphone.com/news/201703/CC6gwUhEAPuG1kvN.html 周志华gcforest

https://www.douban.com/doulist/3440234/ 台大机器学习基石



